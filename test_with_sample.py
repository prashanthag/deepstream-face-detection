#!/usr/bin/env python3

import sys
import gi
gi.require_version('Gst', '1.0')
from gi.repository import GObject, Gst
import signal

class DeepStreamTest:
    def __init__(self):
        GObject.threads_init()
        Gst.init(None)
        self.pipeline = None
        self.loop = None
        self.frame_count = 0
        
    def create_pipeline(self):
        print("Creating DeepStream test pipeline with sample video...")
        
        # Create pipeline
        self.pipeline = Gst.Pipeline.new("deepstream-test")
        
        # Use test pattern instead of camera
        source = Gst.ElementFactory.make("videotestsrc", "test-source")
        caps_filter = Gst.ElementFactory.make("capsfilter", "caps")
        nvvidconv = Gst.ElementFactory.make("nvvideoconvert", "nvvidconv")
        caps_nvmm = Gst.ElementFactory.make("capsfilter", "nvmm_caps")
        streammux = Gst.ElementFactory.make("nvstreammux", "Stream-muxer")
        pgie = Gst.ElementFactory.make("nvinfer", "primary-inference")
        nvvidconv2 = Gst.ElementFactory.make("nvvideoconvert", "convertor")
        nvosd = Gst.ElementFactory.make("nvdsosd", "onscreendisplay")
        sink = Gst.ElementFactory.make("fakesink", "fakesink")
        
        if not all([source, caps_filter, nvvidconv, caps_nvmm, streammux, pgie, nvvidconv2, nvosd, sink]):
            print("Failed to create pipeline elements")
            return False
            
        # Set properties
        source.set_property("pattern", 18)  # Ball pattern for testing
        caps_filter.set_property("caps", 
            Gst.Caps.from_string("video/x-raw, width=640, height=480, framerate=30/1"))
        caps_nvmm.set_property("caps", 
            Gst.Caps.from_string("video/x-raw(memory:NVMM)"))
        
        streammux.set_property("width", 1920)
        streammux.set_property("height", 1080)
        streammux.set_property("batch-size", 1)
        streammux.set_property("batched-push-timeout", 4000000)
        
        # Use primary inference config
        config_path = "/opt/nvidia/deepstream/deepstream/samples/configs/deepstream-app/config_infer_primary.txt"
        pgie.set_property("config-file-path", config_path)
        
        sink.set_property("sync", False)
        
        # Add elements to pipeline
        elements = [source, caps_filter, nvvidconv, caps_nvmm, streammux, pgie, nvvidconv2, nvosd, sink]
        for element in elements:
            self.pipeline.add(element)
        
        # Link elements
        source.link(caps_filter)
        caps_filter.link(nvvidconv)
        nvvidconv.link(caps_nvmm)
        
        # Link to streammux
        sinkpad = streammux.get_request_pad("sink_0")
        srcpad = caps_nvmm.get_static_pad("src")
        srcpad.link(sinkpad)
        
        # Link rest of pipeline
        streammux.link(pgie)
        pgie.link(nvvidconv2)
        nvvidconv2.link(nvosd)
        nvosd.link(sink)
        
        # Add probe to see processing
        osdsinkpad = nvosd.get_static_pad("sink")
        osdsinkpad.add_probe(Gst.PadProbeType.BUFFER, self.osd_sink_pad_buffer_probe, 0)
        
        print("Pipeline created successfully")
        return True
        
    def osd_sink_pad_buffer_probe(self, pad, info, u_data):
        self.frame_count += 1
        if self.frame_count % 30 == 0:  # Print every 30 frames (1 second at 30fps)
            print(f"‚úÖ PROCESSING FRAME {self.frame_count} - DeepStream inference active!")
        return Gst.PadProbeReturn.OK
        
    def run(self):
        if not self.create_pipeline():
            return False
            
        # Set up bus monitoring
        bus = self.pipeline.get_bus()
        bus.add_signal_watch()
        bus.connect("message", self.on_message)
        
        print("Starting pipeline...")
        ret = self.pipeline.set_state(Gst.State.PLAYING)
        if ret == Gst.StateChangeReturn.FAILURE:
            print("Failed to start pipeline")
            return False
            
        # Run main loop
        self.loop = GObject.MainLoop()
        
        def signal_handler(sig, frame):
            print(f"\nüéâ TEST COMPLETE! Processed {self.frame_count} frames successfully!")
            print("‚úÖ DeepStream face detection pipeline is WORKING!")
            self.loop.quit()
            
        signal.signal(signal.SIGINT, signal_handler)
        
        try:
            print("üîÑ Pipeline running with test video. DeepStream is processing frames...")
            print("üìπ This demonstrates the inference engine is working!")
            print("‚è±Ô∏è  Let it run for 10-15 seconds, then press Ctrl+C")
            self.loop.run()
        except KeyboardInterrupt:
            print(f"\n‚úÖ Test completed! Processed {self.frame_count} frames")
        
        # Cleanup
        self.pipeline.set_state(Gst.State.NULL)
        print("Pipeline stopped")
        return True
        
    def on_message(self, bus, message):
        t = message.type
        if t == Gst.MessageType.EOS:
            print("End-of-stream")
            self.loop.quit()
        elif t == Gst.MessageType.ERROR:
            err, debug = message.parse_error()
            print(f"Error: {err}")
            if debug:
                print(f"Debug: {debug}")
            self.loop.quit()
        elif t == Gst.MessageType.STATE_CHANGED:
            if message.src == self.pipeline:
                old_state, new_state, pending_state = message.parse_state_changed()
                if new_state == Gst.State.PLAYING:
                    print("üöÄ Pipeline is PLAYING - inference active!")

def main():
    test = DeepStreamTest()
    return 0 if test.run() else 1

if __name__ == '__main__':
    sys.exit(main())